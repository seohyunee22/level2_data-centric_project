{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# !pip install \"cleanlab[all]\"\n",
    "# [cleanlab documentation] https://docs.cleanlab.ai/stable/index.html\n",
    "from cleanlab.filter import find_label_issues\n",
    "from cleanlab.dataset import health_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # 병렬처리 off (warning 제거)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CleanLab\n",
    "- train으로 학습 후 train을 evaluate 한 결과와 비교\n",
    "- 라벨링 이슈를 탐지할 수 있는 패키지\n",
    "- 학습시킨 모델을 이용하여 수정할 수 있는 데이터셋 이슈를 발견한 다음, 이를 이용하여 더 나은 모델을 학습할 수 있게 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### health_summary() \n",
    "- 데이터셋 라벨별로 이슈를 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def health_summary(data, dataset_test) :\n",
    "    \"\"\"\n",
    "        data (dataframe) : 원본 train (before inference)\n",
    "        dataset_test (dataframe) : output (after inference)    \n",
    "    \"\"\"\n",
    "    \n",
    "    class_names=[0,1,2,3,4,5,6]\n",
    "    health_summary(data['target'], np.array(dataset_test['probs']), class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find_label_issues()\n",
    "- mis-label이 의심되는 행이 출력\n",
    "- probs를 저장하는 코드로 baseline 수정 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label_issues(data, dataset_test, csv_file):\n",
    "    \"\"\"\n",
    "        data (dataframe) : 원본 train (before inference)\n",
    "        dataset_test (dataframe) : output (after inference). probs를 저장하는 코드로 baseline 수정 필요\n",
    "        csv_file (str) : label issues 결과를 저장할 csv 파일 이름        \n",
    "    \"\"\"\n",
    "    \n",
    "    ordered_label_issues = find_label_issues(\n",
    "        labels=data['target'],  # 데이터셋 라벨\n",
    "        pred_probs=np.array(dataset_test['probs']),  # 정답 예측 확률\n",
    "        return_indices_ranked_by='self_confidence',\n",
    "    )\n",
    "\n",
    "    # write mode로 csv 파일 open\n",
    "    with open(csv_file, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        # Create a CSV writer object\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "\n",
    "        if os.stat(csv_file).st_size == 0:\n",
    "            csvwriter.writerow(['text', 'target(raw)', 'target(predict)'])\n",
    "\n",
    "        for issue in ordered_label_issues:\n",
    "            row_data = [\n",
    "                dataset_test.iloc[issue]['text'],\n",
    "                data.iloc[issue]['target'],\n",
    "                dataset_test.iloc[issue]['target']\n",
    "            ]\n",
    "            csvwriter.writerow(row_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    csv_file = \"mis_labeling.csv\"               # label issues 결과를 저장할 csv 파일\n",
    "    data = pd.read_csv(\"train.csv\")             # 원본 train csv 파일\n",
    "    dataset_test = pd.read_csv(\"output.csv\")    # train csv evaluate output 파일\n",
    "    find_label_issues(data, dataset_test, csv_file)\n",
    "    health_summary(data, dataset_test)\n",
    "  \n",
    "  \n",
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
